{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRID-Download&Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FHPvduY9cBmy"
      ],
      "mount_file_id": "1P9iZ_0qZNZcyNmZ_pm1Sqm35Tsb5ohbh",
      "authorship_tag": "ABX9TyNaex7c7dI58hl81H+0+KOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YantCaccia/Tirocinio/blob/main/GRID_Download%26Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ivBvBENPLL5"
      },
      "source": [
        "Word-level prediction (we tryin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiEQvf2wJDyP"
      },
      "source": [
        "#Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRe9NK4RI_9d"
      },
      "source": [
        "%%shell\n",
        "#preparing for download \n",
        "mkdir \"gridcorpus\"\n",
        "cd \"gridcorpus\"\n",
        "mkdir \"raw\"\n",
        "cd \"raw\" && mkdir \"video\" \"align\"\n",
        "\n",
        "for i in `seq $1 $2`\n",
        "do\n",
        "    printf \"\\n\\n------------------------- Downloading $i th speaker -------------------------\\n\\n\"\n",
        "    \n",
        "    #download the video of the ith speaker\n",
        "    cd \"align\" && curl \"http://spandh.dcs.shef.ac.uk/gridcorpus/s$i/align/s$i.tar\" > \"s$i.tar\" && cd ..\n",
        "    cd \"video\" && curl \"http://spandh.dcs.shef.ac.uk/gridcorpus/s$i/video/s$i.mpg_vcd.zip\" > \"s$i.zip\" && cd ..\n",
        "\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtzCU-__RBE-"
      },
      "source": [
        "#Unzip raw from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfcLBMcCRJbI"
      },
      "source": [
        "#10 min exec time\n",
        "%%shell\n",
        "cd /content\n",
        "mkdir \"intermediateDataset\"\n",
        "cd intermediateDataset\n",
        "for i in `seq 1 20`\n",
        "do\n",
        "  unzip -q \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/gridcorpus/raw/video/s$i.zip\" -d \"/content/intermediateDataset\"\n",
        "  tar -xf \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/gridcorpus/raw/align/s$i.tar\" -C \"/content/intermediateDataset/s$i\"\n",
        "done\n",
        "for i in `seq 22 34`\n",
        "do\n",
        "  unzip -q \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/gridcorpus/raw/video/s$i.zip\" -d \"/content/intermediateDataset\"\n",
        "  tar -xf \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/gridcorpus/raw/align/s$i.tar\" -C \"/content/intermediateDataset/s$i\"\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4azyerkBYdte"
      },
      "source": [
        "#Structure dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC2nC7KaYnjL"
      },
      "source": [
        "#exec time 4h 30m\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import concurrent.futures\n",
        "import cv2\n",
        "import urllib.request as urlreq\n",
        "import subprocess\n",
        "\n",
        "myPath = \"/content/intermediateDataset\"\n",
        "VIDEO_MARGIN = 0.02\n",
        "PIXEL_MARGIN = 15\n",
        "\n",
        "# -- FACE DETECTION GOODIES -- #\n",
        "# save face detection algorithm's url in haarcascade_url variable\n",
        "haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
        "\n",
        "# save face detection algorithm's name as haarcascade\n",
        "haarcascade = \"haarcascade_frontalface_alt2.xml\"\n",
        "\n",
        "# check if file is in working directory\n",
        "if not (haarcascade in os.listdir(os.curdir)):\n",
        "  urlreq.urlretrieve(haarcascade_url, haarcascade)\n",
        "# ---------------------------- #\n",
        "\n",
        "# -- FACE LANDMARKS GOODIES -- #\n",
        "# save facial landmark detection model's url in LBFmodel_url variable\n",
        "LBFmodel_url = \"https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml\"\n",
        "\n",
        "# save facial landmark detection model's name as LBFmodel\n",
        "LBFmodel = \"LFBmodel.yaml\"\n",
        "\n",
        "# check if file is in working directory (if not download it)\n",
        "if not (LBFmodel in os.listdir(os.curdir)):\n",
        "  urlreq.urlretrieve(LBFmodel_url, LBFmodel)\n",
        "\n",
        "# ---------------------------- #\n",
        "\n",
        "# ---- UTILITY FUNCTIONS ---- #\n",
        "def fromFrameToSec(frame):\n",
        "  TOT_FRAME = 75\n",
        "  TOT_S = 3\n",
        "  normFrame = (frame + 500) / 1000\n",
        "  return ((TOT_S * normFrame)/(TOT_FRAME))\n",
        "\n",
        "def extractClassSentenceEdition(fileName):\n",
        "    with open(fileName, \"r\") as f:\n",
        "        return \"\".join(word.capitalize() for word in [line.split()[2] for line in f.readlines()] if word not in [\"sil\", \"sp\"])\n",
        "\n",
        "def extractClassWordEdition(fileName):\n",
        "    with open(fileName, \"r\") as f:\n",
        "        for line in f.readlines():\n",
        "            info = line.split()\n",
        "            startFrame = int(info[0])\n",
        "            finishFrame = int(info[1])\n",
        "            word = info[2]\n",
        "            if word not in  [\"sil\", \"sp\"]:\n",
        "                yield (fromFrameToSec(startFrame) - VIDEO_MARGIN, fromFrameToSec(finishFrame) + VIDEO_MARGIN, word)\n",
        "\n",
        "def extractInfoFromEntry(entry, pathToSpeaker):\n",
        "  id = entry[:-4]\n",
        "  filename = id + \".align\"\n",
        "  srcPath = os.path.join(pathToSpeaker, entry)\n",
        "  return (id, filename, srcPath)\n",
        "\n",
        "def extractMouthLandmarkFromVideo(videoPath):\n",
        "\n",
        "  # from video to single frame (frame to be used as \"image\")\n",
        "  cap = cv2.VideoCapture(videoPath)\n",
        "  cap.set(1, 1); # primo argomento è una costante, secondo argomento è il frame che voglio\n",
        "  _, image = cap.read() # primo valore restituito è bool (successful or not), secondo valore è il frame\n",
        "\n",
        "  # create an instance of the Face Detection Cascade Classifier\n",
        "  detector = cv2.CascadeClassifier(haarcascade)\n",
        "\n",
        "  # detect faces using the haarcascade classifier on the \"image\"\n",
        "  faces = detector.detectMultiScale(image)\n",
        "\n",
        "  # create an instance of the Facial landmark Detector with the model\n",
        "  landmark_detector  = cv2.face.createFacemarkLBF()\n",
        "  landmark_detector.loadModel(LBFmodel)\n",
        "\n",
        "  # Detect landmarks on \"image\"\n",
        "  _, landmarks = landmark_detector.fit(image, faces)\n",
        "\n",
        "  # coordinates of mouth landmarks (48th element in the landmarks array)\n",
        "  mouthX, mouthY = landmarks[0][0][48]\n",
        "\n",
        "  return (mouthX - PIXEL_MARGIN, mouthY - PIXEL_MARGIN)\n",
        "\n",
        "def extractMouthLandmarkFromVideoWrapper(pathToSpeaker):\n",
        "  # mouth info from first video in the directory\n",
        "  for entry in os.listdir(pathToSpeaker):\n",
        "    if entry.endswith(\".mpg\"):\n",
        "      mouthX, mouthY = extractMouthLandmarkFromVideo(os.path.join(pathToSpeaker, entry))\n",
        "      return (mouthX, mouthY) #loop should end\n",
        "# --------------------------- #\n",
        "\n",
        "\n",
        "def workerWordEdition(i, entry, pathToSpeaker, mouthX, mouthY):\n",
        "  if entry.endswith(\".mpg\"):\n",
        "    id, filename, srcPath = extractInfoFromEntry(entry, pathToSpeaker) # info sul nome del file\n",
        "    for wordInfo in extractClassWordEdition(os.path.join(pathToSpeaker, \"align\", filename)): # per ogni parola nel video\n",
        "      startTime, finishTime, word = wordInfo\n",
        "      title = \"WORD{}SP{}SEN{}.mpg\".format(word, i, id)\n",
        "      #metto il video tagliato in /{word}/{title}.mpg\n",
        "      dstDirPath = os.path.join(\"/content/myFinalDataset\", word)\n",
        "      dstPath = os.path.join(dstDirPath, title)\n",
        "      if not os.path.exists(dstDirPath):\n",
        "        os.mkdir(dstDirPath)\n",
        "      #trim, crop, greyscale, remove audio and save video\n",
        "      os.system(\"ffmpeg -i {input} -ss 00:00:{sTime} -to 00:00:{fTime} -fflags +genpts -an -vf crop=80:40:{topLeftX}:{topLeftY},format=gray {output}\".format(sTime=startTime, input=srcPath, fTime=finishTime, topLeftX = mouthX, topLeftY = mouthY, output=dstPath))\n",
        "      #this will check the number of frame in the video just created\n",
        "      command = \"ffmpeg -i {} -map 0:v:0 -c copy -f null -y /dev/null 2>&1 | grep -Eo 'frame= *[0-9]+ *' | grep -Eo '[0-9]+' | tail -1\".format(dstPath)\n",
        "      try:\n",
        "        frameNumber = int(subprocess.run(command, capture_output=True, text=True, shell=True).stdout)\n",
        "        #delete video if its frame count is < 3 (not very clever but still)\n",
        "        if frameNumber < 3:\n",
        "          os.system(\"rm {}\".format(dstPath))\n",
        "      except ValueError:\n",
        "        #frameCount not available -> video corrupted -> delete it!\n",
        "        os.system(\"rm {}\".format(dstPath))\n",
        "        pass\n",
        "\n",
        "#os.system(\"rm -rf myFinalDataset/\") #just to be sure\n",
        "os.mkdir(\"/content/myFinalDataset\")\n",
        "\n",
        "#for i in [*range(1, 21), *range(22, 35)]:\n",
        "for i in [*range(1,21), *range(22,35)]:\n",
        "  pathToSpeaker = os.path.join(myPath, \"s{}\".format(str(i)))\n",
        "  mouthX, mouthY = extractMouthLandmarkFromVideoWrapper(pathToSpeaker) #done once per speaker to ease computation time\n",
        "  with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    for entry in os.listdir(pathToSpeaker):\n",
        "      #workerWordEdition(i, entry, pathToSpeaker, mouthX, mouthY)\n",
        "      executor.submit(workerWordEdition, i, entry, pathToSpeaker, mouthX, mouthY)\n",
        "  \n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fEbB4skH5v9"
      },
      "source": [
        "#Zip final dataset on Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3moK23qcNGCJ"
      },
      "source": [
        "#exec time 4m\n",
        "!zip -r \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/finalDataset/myFinalDatasetCroppedSentenceEdition.zip\" \"/content/myFinalDataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGAa1bMEdBzA"
      },
      "source": [
        "!rm -rf \"/content/intermediateDataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4dP1EHKIBzm"
      },
      "source": [
        "# Unzip and delete those with nFrames < 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXMU_DSjH4Qz"
      },
      "source": [
        "!rm -rf \"/content/myDataset\"\n",
        "!unzip -qq \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/finalDataset/myFinalDatasetCropped.zip\" -d \"/content/\"\n",
        "!mv \"/content/content/myFinalDataset/\" \"/content/myDataset\"\n",
        "!rm -rf \"/content/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeJ5RM4UIL8m"
      },
      "source": [
        "import os, subprocess\n",
        "\n",
        "deletedCount = 0\n",
        "\n",
        "#this will check the number of frame in the videos just created\n",
        "for root, dirs, files in os.walk(\"/content/myDataset\"):\n",
        "  for video in files:\n",
        "    try:\n",
        "      filePath = os.path.join(root, video)\n",
        "      command = \"ffmpeg -i {} -map 0:v:0 -c copy -f null -y /dev/null 2>&1 | grep -Eo 'frame= *[0-9]+ *' | grep -Eo '[0-9]+' | tail -1\".format(filePath)\n",
        "      frameNumber = int(subprocess.run(command, capture_output=True, text=True, shell=True).stdout)\n",
        "      #delete video if its frame count is < 3 (not very clever but still)\n",
        "      if frameNumber < 3:\n",
        "        os.system(\"rm {}\".format(filePath))\n",
        "        print(\"Removed: \", filePath)\n",
        "        deletedCount = deletedCount + 1\n",
        "    except ValueError:\n",
        "      #numberOfFrames not available -> video corrupted -> delete it!\n",
        "      os.system(\"rm {}\".format(filePath))\n",
        "      print(\"Removed: \", filePath, \"because of ValueError\")\n",
        "      deletedCount = deletedCount + 1\n",
        "print(\"Tot. delated: \", deletedCount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXrE1xf2LSgo"
      },
      "source": [
        "!zip -q -r \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/finalDataset/myFinalDatasetCroppedNewEdition.zip\" \"/content/myDataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbvQY1_-7Rpv"
      },
      "source": [
        "#tbd\n",
        "#test if file removing worked\n",
        "\n",
        "!find \"/content/myDataset/again\" -name \"WORDagainSP8SENbgag6a.mpg\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}