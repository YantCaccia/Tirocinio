{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRID-VSR.ipynb",
      "provenance": [],
      "mount_file_id": "14NeCrQTWt4AfewqePk9ViUkGUg73T1Xt",
      "authorship_tag": "ABX9TyMrAmPJQ1lnmVINWsbxFm9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YantCaccia/Tirocinio/blob/main/GRID_VSR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABj6kpZiIdv6"
      },
      "source": [
        "#Unzip dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBBx9EFuIjJ-"
      },
      "source": [
        "!rm -rf \"/content/sample_data\"\n",
        "!rm -rf \"/content/myFinalDataset\"\n",
        "!rm -rd \"/content/myDataset\"\n",
        "!unzip -qq \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/finalDataset/myFinalDatasetCroppedNewEdition.zip\" -d \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ngH6ArYe72"
      },
      "source": [
        "I'm stupid so let's move the files in the correct directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxTujohxXTVt"
      },
      "source": [
        "!mv \"/content/content/myDataset/\" \"/content/myDataset\"\n",
        "!rm -rf \"/content/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtpe2tj95QV5"
      },
      "source": [
        "#tbd\n",
        "#test if file removing worked\n",
        "\n",
        "!find \"/content/myDataset/again\" -name \"WORDagainSP8SENbgag6a.mpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXubS0b2Jpk0"
      },
      "source": [
        "#Video generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_X-iSs4Jtyn"
      },
      "source": [
        "!pip install keras-video-generators\n",
        "#the following line is mandatory to solve a bug in the current release of keras-video-generators library\n",
        "!sed -i '18s/.*/from tensorflow.keras.utils import Sequence/' \"/usr/local/lib/python3.7/dist-packages/keras_video/generator.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmMimRzscX-q"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import glob\n",
        "from keras_video import VideoFrameGenerator\n",
        "import keras_video.utils\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "\n",
        "# use sub directories names as classes\n",
        "classes = [i.split(os.path.sep)[3] for i in glob.glob('/content/myDataset/*')]\n",
        "classes.sort()\n",
        "\n",
        "# some global params\n",
        "SIZE = (80, 40) #(360, 288)\n",
        "CHANNELS = 1\n",
        "NBFRAME = 3\n",
        "BS =  64\n",
        "\n",
        "# pattern to get videos and classes\n",
        "glob_pattern='/content/myDataset/{classname}/*'\n",
        "\n",
        "# for data augmentation\n",
        "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=.2,\n",
        "    height_shift_range=.2)\n",
        "\n",
        "# Create video frame generator\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split_val=.15, \n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=data_aug,\n",
        "    use_frame_cache=False)\n",
        "\n",
        "\n",
        "valid = train.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H6zTRBarbm1"
      },
      "source": [
        "# Model creation and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_-IuXVrhIJ"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D, Flatten, GRU, Dropout, TimeDistributed, Dense\n",
        "\n",
        "def build_convnet(shape=(112, 112, 3)):\n",
        "    momentum = .9\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # flatten...\n",
        "    model.add(GlobalMaxPool2D())\n",
        "    return model\n",
        "\n",
        "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    convnet = build_convnet(shape[1:])\n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    # add the convnet with (5, 112, 112, 3) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
        "model = action_model(INSHAPE, len(classes))\n",
        "optimizer = keras.optimizers.Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "EPOCHS=10\n",
        "\n",
        "# create a \"chkp\" directory before to run that\n",
        "# because ModelCheckpoint will write models inside\n",
        "path = \"/content/chkp\"\n",
        "if not os.path.exists(path):\n",
        "  os.mkdir(path)\n",
        "\n",
        "class ClearMemory(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        keras.backend.clear_session()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        verbose=1),\n",
        "    keras.callbacks.EarlyStopping(patience=7),\n",
        "    ClearMemory()\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN2GO5NL8AAT"
      },
      "source": [
        "!cp -r \"/content/chkp\" \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/weights/1509\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQN23FzkfXHP"
      },
      "source": [
        "# Model creation and training (TBR, just to quickly test the library)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF96kPwwfcGh"
      },
      "source": [
        "import gc\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import ConvLSTM2D, Dropout, Flatten, Dense, SimpleRNN\n",
        "\n",
        "class ClearMemory(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "#model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (NBFRAME, SIZE[1], SIZE[0], CHANNELS)))\n",
        "model.add(SimpleRNN(units = 64, return_sequences = False, input_shape = (NBFRAME, SIZE[1], SIZE[0], CHANNELS)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(51, activation = \"relu\"))\n",
        "\n",
        "opt = keras.optimizers.Adam(0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"], run_eagerly=True)\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(patience=7)\n",
        "callbacks = [earlystop, ClearMemory()]\n",
        "\n",
        "history = model.fit(x = train, epochs=10, batch_size = BS, callbacks=callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}