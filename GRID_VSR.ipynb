{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABj6kpZiIdv6"
   },
   "source": [
    "#Unzip dataset from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBBx9EFuIjJ-"
   },
   "outputs": [],
   "source": [
    "!rm -rf \"/content/sample_data\"\n",
    "!rm -rf \"/content/myFinalDataset\"\n",
    "!rm -rd \"/content/myDataset\"\n",
    "!unzip -qq \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/finalDataset/myFinalDatasetCroppedNewEdition.zip\" -d \"/content/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4ngH6ArYe72"
   },
   "source": [
    "I'm stupid so let's move the files in the correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxTujohxXTVt"
   },
   "outputs": [],
   "source": [
    "!mv \"/content/content/myDataset/\" \"/content/myDataset\"\n",
    "!rm -rf \"/content/content\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXubS0b2Jpk0"
   },
   "source": [
    "#Video generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_X-iSs4Jtyn"
   },
   "outputs": [],
   "source": [
    "!pip install keras-video-generators\n",
    "#the following line is mandatory to solve a bug in the current release of keras-video-generators library\n",
    "!sed -i '18s/.*/from tensorflow.keras.utils import Sequence/' \"/usr/local/lib/python3.7/dist-packages/keras_video/generator.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZmMimRzscX-q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class again, validation count: 2466, train count: 5755\n",
      "class at, validation count: 2428, train count: 5667\n",
      "class bin, validation count: 2454, train count: 5727\n",
      "class blue, validation count: 2467, train count: 5759\n",
      "class by, validation count: 2465, train count: 5754\n",
      "class lay, validation count: 2514, train count: 5866\n",
      "class now, validation count: 2466, train count: 5757\n",
      "class place, validation count: 2475, train count: 5778\n",
      "class please, validation count: 2468, train count: 5759\n",
      "class red, validation count: 2466, train count: 5757\n",
      "class set, validation count: 2424, train count: 5658\n",
      "class soon, validation count: 2466, train count: 5757\n",
      "class white, validation count: 2466, train count: 5754\n",
      "class with, validation count: 2465, train count: 5753\n",
      "Total data: 14 classes for 80501 files for train\n",
      "Total data: 14 classes for 34490 files for validation\n"
     ]
    }
   ],
   "source": [
    "import os, glob, tensorflow, keras_video.utils\n",
    "from keras_video import VideoFrameGenerator\n",
    "from tensorflow import keras\n",
    "\n",
    "# use sub directories names as classes\n",
    "datasetPath = os.path.join('..', 'contentOld', 'myDatasetExperimental')\n",
    "classes = [i.split(os.path.sep)[3] for i in glob.glob(os.path.join(datasetPath, '*'))]\n",
    "classes.sort()\n",
    "\n",
    "# some global params\n",
    "SIZE = (80, 40)\n",
    "CHANNELS = 1\n",
    "NBFRAME = 5\n",
    "BS =  32\n",
    "\n",
    "# pattern to get videos and classes\n",
    "#glob_pattern='/content/myDataset/{classname}/*'\n",
    "#glob_pattern_train = os.path.join(datasetPath, 'train', '{classname}', '*')\n",
    "#glob_pattern_val = os.path.join(datasetPath, 'val', '{classname}', '*')\n",
    "glob_pattern_train = os.path.join(datasetPath, '{classname}', '*')\n",
    "\n",
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=False,\n",
    "    rotation_range=3,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)\n",
    "\n",
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern_train,\n",
    "    nb_frames=NBFRAME, \n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=False,\n",
    "    split_val=0.3)\n",
    "\n",
    "\n",
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mtrjD8KjpCE"
   },
   "source": [
    "# Goodies (will be useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "99wXeGxdjvnZ"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras.layers import AveragePooling3D, AveragePooling2D, Conv2D, Conv3D, Dropout, MaxPooling2D, MaxPooling3D, BatchNormalization, TimeDistributed, LSTM, Dense, Flatten, GlobalMaxPool2D\n",
    "\n",
    "#useful vars\n",
    "EPOCHS = 100\n",
    "INPUTSHAPE = (NBFRAME,) + SIZE + (CHANNELS,)\n",
    "NUMBEROFCLASSES = len(classes)\n",
    "\n",
    "class ClearMemory(tensorflow.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        tensorflow.keras.backend.clear_session()\n",
    "\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "#path = os.path.join('.', 'content', 'chkp')\n",
    "#path = 'C:\\\\Users\\\\vrlab\\\\Desktop\\\\ANTONIO_CACCIAPUOTI\\\\content\\\\chkp'\n",
    "path = 'C:\\\\Users\\\\vrlab\\\\Desktop\\\\ANTONIO_CACCIAPUOTI\\\\contentOld\\\\chkp\\\\useless'\n",
    "if not os.path.exists(path):\n",
    "  os.mkdir(path)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1, patience=3, min_lr=0.0001, monitor=\"val_acc\", factor=0.8, min_delta=0.003),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(path, 'weights.{epoch:02d}.hdf5'),\n",
    "        verbose=1),\n",
    "    keras.callbacks.EarlyStopping(patience=10, monitor=\"val_acc\", min_delta=0.001),\n",
    "    ClearMemory()\n",
    "]\n",
    "\n",
    "opt = keras.optimizers.Adam(0.01) #0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQN23FzkfXHP"
   },
   "source": [
    "# Model creation and training (ConvLSTM2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XF96kPwwfcGh"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Dropout, Flatten, Dense, SimpleRNN, MaxPooling3D\n",
    "\n",
    "def makeConvLSTM2D():\n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True, data_format = \"channels_last\", input_shape = (NBFRAME, SIZE[1], SIZE[0], CHANNELS)))\n",
    "  model.add(Dropout(0.2))\n",
    "  #model.add(AveragePooling3D()) #reduce dimension\n",
    "  #model.add(BatchNormalization()) #standardize inputs\n",
    "    \n",
    "  model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = False))\n",
    "  model.add(Dropout(0.2))\n",
    "  #model.add(AveragePooling2D())\n",
    "  #model.add(BatchNormalization())\n",
    "    \n",
    "  model.add(Flatten())\n",
    "  \n",
    "  #model.add(Dense(512, activation=\"relu\"))\n",
    "  #model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(Dense(256, activation=\"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "\n",
    "  model.add(Dense(128, activation=\"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  \n",
    "  model.add(Dense(NUMBEROFCLASSES, activation = \"softmax\"))\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObHhIY9DPi5W"
   },
   "source": [
    "# Model creation and training (TimeDistributed CNN + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tqj1b_ajPpFM"
   },
   "outputs": [],
   "source": [
    "def makeCNN():\n",
    "  model = keras.Sequential()\n",
    "  \n",
    "  model.add(Conv2D(filters = 64, kernel_size = (3,3), input_shape = (SIZE[1], SIZE[0], CHANNELS), activation = 'relu'))\n",
    "  #model.add(BatchNormalization()) #standardize inputs\n",
    "  #model.add(MaxPooling2D()) #reduce dimension\n",
    "  model.add(Dropout(0.2))\n",
    "    \n",
    "  model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
    "  #model.add(BatchNormalization())\n",
    "  #model.add(MaxPooling2D())\n",
    "  model.add(Dropout(0.2))\n",
    "    \n",
    "  model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
    "  #model.add(BatchNormalization())\n",
    "  #model.add(MaxPooling2D())\n",
    "  model.add(Dropout(0.2))\n",
    "    \n",
    "  model.add(Flatten())\n",
    "\n",
    "  return model\n",
    "\n",
    "def makeRNN():\n",
    "  #make cnn first\n",
    "  cnn = makeCNN()\n",
    "  \n",
    "  #create model\n",
    "  model = keras.Sequential()\n",
    "  \n",
    "  #add cnn\n",
    "  #model.add(TimeDistributed(cnn, input_shape=INPUTSHAPE))\n",
    "  model.add(TimeDistributed(cnn, input_shape = (NBFRAME, SIZE[1], SIZE[0], CHANNELS)))\n",
    "\n",
    "  #add rnn\n",
    "  model.add(LSTM(64))\n",
    "  \n",
    "  #lets decide\n",
    "  #model.add(Dense(1024, activation='relu'))\n",
    "  #model.add(Dropout(.2))\n",
    "  \n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  \n",
    "  #model.add(Dense(128, activation='relu'))\n",
    "  #model.add(Dropout(.2))\n",
    "  \n",
    "  model.add(Dense(NUMBEROFCLASSES, activation='softmax'))\n",
    "\n",
    "  return model\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9itivDL6PYX"
   },
   "source": [
    "# Model creation (3D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fCiN_EPR6bSb"
   },
   "outputs": [],
   "source": [
    "def make3DCNN():\n",
    "  model = keras.Sequential()  \n",
    "  \n",
    "  model.add(Conv3D(64, kernel_size=(1, 4, 4), padding='same', strides=(1,1,1), data_format = \"channels_last\", input_shape = (SIZE[1], SIZE[0], NBFRAME, CHANNELS)))\n",
    "  model.add(MaxPooling3D(pool_size=(1, 4, 4), padding='same', strides=(1,1,1)))\n",
    "  #model.add(BatchNormalization(center=True, scale=True))\n",
    "  model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(Conv3D(64, kernel_size=(1, 4, 4), padding='same', strides=(1,1,1)))\n",
    "  model.add(MaxPooling3D(pool_size=(1, 4, 4), padding='same', strides=(1,1,1)))\n",
    "  #model.add(BatchNormalization(center=True, scale=True))\n",
    "  model.add(Dropout(0.2))\n",
    "  \n",
    "  model.add(Flatten(data_format='channels_last'))\n",
    "  \n",
    "  #model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "  #model.add(Dropout(0.2))\n",
    "  \n",
    "  model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dropout(0.2))\n",
    "  \n",
    "  model.add(Dense(NUMBEROFCLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9m8gbC76WOW"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "czT91Azh_OGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 5, 161024)         74496     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                41238784  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                3598      \n",
      "=================================================================\n",
      "Total params: 41,333,518\n",
      "Trainable params: 41,333,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6352 - acc: 0.0725\n",
      "Epoch 00001: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.01.hdf5\n",
      "2515/2515 [==============================] - 1316s 523ms/step - loss: 2.6352 - acc: 0.0725 - val_loss: 2.6343 - val_acc: 0.0758\n",
      "Epoch 2/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6341 - acc: 0.0737\n",
      "Epoch 00002: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.02.hdf5\n",
      "2515/2515 [==============================] - 637s 253ms/step - loss: 2.6341 - acc: 0.0737 - val_loss: 2.6356 - val_acc: 0.0759\n",
      "Epoch 3/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6342 - acc: 0.0740\n",
      "Epoch 00003: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.03.hdf5\n",
      "2515/2515 [==============================] - 640s 255ms/step - loss: 2.6342 - acc: 0.0740 - val_loss: 2.6336 - val_acc: 0.0745\n",
      "Epoch 4/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6344 - acc: 0.0737\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.04.hdf5\n",
      "2515/2515 [==============================] - 641s 255ms/step - loss: 2.6344 - acc: 0.0737 - val_loss: 2.6335 - val_acc: 0.0744\n",
      "Epoch 5/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6340 - acc: 0.0751\n",
      "Epoch 00005: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.05.hdf5\n",
      "2515/2515 [==============================] - 642s 255ms/step - loss: 2.6340 - acc: 0.0751 - val_loss: 2.6340 - val_acc: 0.0744\n",
      "Epoch 6/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6339 - acc: 0.0754\n",
      "Epoch 00006: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.06.hdf5\n",
      "2515/2515 [==============================] - 642s 255ms/step - loss: 2.6339 - acc: 0.0754 - val_loss: 2.6341 - val_acc: 0.0743\n",
      "Epoch 7/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6339 - acc: 0.0748\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.07.hdf5\n",
      "2515/2515 [==============================] - 641s 255ms/step - loss: 2.6339 - acc: 0.0748 - val_loss: 2.6339 - val_acc: 0.0758\n",
      "Epoch 8/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6337 - acc: 0.0744\n",
      "Epoch 00008: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.08.hdf5\n",
      "2515/2515 [==============================] - 641s 255ms/step - loss: 2.6337 - acc: 0.0744 - val_loss: 2.6339 - val_acc: 0.0745\n",
      "Epoch 9/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6335 - acc: 0.0754\n",
      "Epoch 00009: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.09.hdf5\n",
      "2515/2515 [==============================] - 640s 255ms/step - loss: 2.6335 - acc: 0.0754 - val_loss: 2.6346 - val_acc: 0.0722\n",
      "Epoch 10/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6337 - acc: 0.0738\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0051199994981288915.\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.10.hdf5\n",
      "2515/2515 [==============================] - 641s 255ms/step - loss: 2.6337 - acc: 0.0738 - val_loss: 2.6339 - val_acc: 0.0742\n",
      "Epoch 11/100\n",
      "2515/2515 [==============================] - ETA: 0s - loss: 2.6336 - acc: 0.0727\n",
      "Epoch 00011: saving model to C:\\Users\\vrlab\\Desktop\\ANTONIO_CACCIAPUOTI\\contentOld\\chkp\\useless\\weights.11.hdf5\n",
      "2515/2515 [==============================] - 641s 255ms/step - loss: 2.6336 - acc: 0.0727 - val_loss: 2.6336 - val_acc: 0.0759\n"
     ]
    }
   ],
   "source": [
    "## lets fit\n",
    "    \n",
    "model = makeRNN()\n",
    "model.summary()\n",
    "model.compile(opt, 'categorical_crossentropy', metrics=['acc'], run_eagerly=True)\n",
    "history = model.fit(train, validation_data=valid, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('C:\\\\Users\\\\vrlab\\\\Desktop\\\\ANTONIO_CACCIAPUOTI\\\\contentOld\\\\chkp\\\\2910ConvLSTM2D\\\\history.pickle', 'wb') as handle:\n",
    "    pickle.dump(history.history, handle)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOQt7UiBu6BrJhI44+SYDUW",
   "mount_file_id": "14NeCrQTWt4AfewqePk9ViUkGUg73T1Xt",
   "name": "GRID-VSR.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
