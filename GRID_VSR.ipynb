{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GRID-VSR.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "14NeCrQTWt4AfewqePk9ViUkGUg73T1Xt",
      "authorship_tag": "ABX9TyOQt7UiBu6BrJhI44+SYDUW"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABj6kpZiIdv6"
      },
      "source": [
        "#Unzip dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBBx9EFuIjJ-"
      },
      "source": [
        "!rm -rf \"/content/sample_data\"\n",
        "!rm -rf \"/content/myFinalDataset\"\n",
        "!rm -rd \"/content/myDataset\"\n",
        "!unzip -qq \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/finalDataset/myFinalDatasetCroppedNewEdition.zip\" -d \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ngH6ArYe72"
      },
      "source": [
        "I'm stupid so let's move the files in the correct directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxTujohxXTVt"
      },
      "source": [
        "!mv \"/content/content/myDataset/\" \"/content/myDataset\"\n",
        "!rm -rf \"/content/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXubS0b2Jpk0"
      },
      "source": [
        "#Video generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_X-iSs4Jtyn"
      },
      "source": [
        "!pip install keras-video-generators\n",
        "#the following line is mandatory to solve a bug in the current release of keras-video-generators library\n",
        "!sed -i '18s/.*/from tensorflow.keras.utils import Sequence/' \"/usr/local/lib/python3.7/dist-packages/keras_video/generator.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmMimRzscX-q"
      },
      "source": [
        "import os, glob, tensorflow, keras_video.utils\n",
        "from keras_video import VideoFrameGenerator\n",
        "from tensorflow import keras\n",
        "\n",
        "# use sub directories names as classes\n",
        "classes = [i.split(os.path.sep)[3] for i in glob.glob('/content/myDataset/*')]\n",
        "classes.sort()\n",
        "\n",
        "# some global params\n",
        "SIZE = (80, 40)\n",
        "CHANNELS = 1\n",
        "NBFRAME = 3\n",
        "BS =  64\n",
        "\n",
        "# pattern to get videos and classes\n",
        "glob_pattern='/content/myDataset/{classname}/*'\n",
        "\n",
        "# for data augmentation\n",
        "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=.2,\n",
        "    height_shift_range=.2)\n",
        "\n",
        "# Create video frame generator\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split_val=.15, \n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=data_aug,\n",
        "    use_frame_cache=False)\n",
        "\n",
        "\n",
        "valid = train.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mtrjD8KjpCE"
      },
      "source": [
        "# Goodies (will be useful)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99wXeGxdjvnZ"
      },
      "source": [
        "import gc\n",
        "from keras.layers import Conv2D, Conv3D, Dropout, MaxPooling2D, MaxPooling3D, BatchNormalization, TimeDistributed, LSTM, Dense, Flatten, GlobalMaxPool2D\n",
        "\n",
        "#useful vars\n",
        "EPOCHS = 10\n",
        "INPUTSHAPE = (NBFRAME,) + SIZE + (CHANNELS,)\n",
        "NUMBEROFCLASSES = len(classes)\n",
        "\n",
        "class ClearMemory(tensorflow.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tensorflow.keras.backend.clear_session()\n",
        "\n",
        "# create a \"chkp\" directory before to run that\n",
        "# because ModelCheckpoint will write models inside\n",
        "path = \"/content/chkp\"\n",
        "if not os.path.exists(path):\n",
        "  os.mkdir(path)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}.hdf5',\n",
        "        verbose=1),\n",
        "    keras.callbacks.EarlyStopping(patience=7),\n",
        "    ClearMemory()\n",
        "]\n",
        "\n",
        "opt = keras.optimizers.Adam(0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H6zTRBarbm1"
      },
      "source": [
        "# Model creation and training (by Patrice Ferlet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_-IuXVrhIJ"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D, Flatten, GRU, Dropout, TimeDistributed, Dense\n",
        "\n",
        "def build_convnet(shape=(112, 112, 3)):\n",
        "    momentum = .9\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # flatten...\n",
        "    model.add(GlobalMaxPool2D())\n",
        "    return model\n",
        "\n",
        "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    convnet = build_convnet(shape[1:])\n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    # add the convnet with (5, 112, 112, 3) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
        "model = action_model(INSHAPE, len(classes))\n",
        "optimizer = keras.optimizers.Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        verbose=1),\n",
        "    keras.callbacks.EarlyStopping(patience=7),\n",
        "    ClearMemory()\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN2GO5NL8AAT"
      },
      "source": [
        "!cp -r \"/content/chkp\" \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/weights/1509\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQN23FzkfXHP"
      },
      "source": [
        "# Model creation and training (ConvLSTM2D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF96kPwwfcGh"
      },
      "source": [
        "import gc\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import ConvLSTM2D, Dropout, Flatten, Dense, SimpleRNN\n",
        "\n",
        "def makeConvLSTM2D():\n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (NBFRAME, SIZE[1], SIZE[0], CHANNELS)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(128, activation=\"relu\"))\n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(Dense(NUMBEROFCLASSES, activation = \"relu\"))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObHhIY9DPi5W"
      },
      "source": [
        "# Model creation and training (TimeDistributed CNN + LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqj1b_ajPpFM"
      },
      "source": [
        "#as of 24/09 this model has 0.17 accuracy\n",
        "\n",
        "def makeCNN():\n",
        "  model = keras.Sequential()\n",
        "  \n",
        "  model.add(Conv2D(filters = 128, kernel_size = (3,3), input_shape = (SIZE[1], SIZE[0], CHANNELS), activation = 'relu'))\n",
        "  model.add(BatchNormalization()) #standardize inputs\n",
        "  model.add(MaxPooling2D()) #reduce dimension\n",
        "  \n",
        "  model.add(Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D())\n",
        "  \n",
        "  model.add(Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  return model\n",
        "\n",
        "def makeRNN():\n",
        "  #make cnn first\n",
        "  cnn = makeCNN()\n",
        "  \n",
        "  #create model\n",
        "  model = keras.Sequential()\n",
        "  \n",
        "  #add cnn\n",
        "  #model.add(TimeDistributed(cnn, input_shape=INPUTSHAPE))\n",
        "  model.add(TimeDistributed(cnn, input_shape = (NBFRAME, SIZE[1], SIZE[0], CHANNELS)))\n",
        "\n",
        "  #add rnn\n",
        "  model.add(LSTM(64))\n",
        "  \n",
        "  #lets decide\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(.2))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(.2))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(.2))\n",
        "  model.add(Dense(NUMBEROFCLASSES, activation='softmax'))\n",
        "\n",
        "  return model\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9itivDL6PYX"
      },
      "source": [
        "# Model creation (3D CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCiN_EPR6bSb"
      },
      "source": [
        "def make3DCNN():\n",
        "  model = keras.Sequential()  \n",
        "  \n",
        "  model.add(Conv3D(32, kernel_size=(1, 4, 4), padding='same', strides=(1,1,1), activation='relu', kernel_initializer='he_uniform', data_format = \"channels_last\", input_shape = (SIZE[1], SIZE[0], NBFRAME, CHANNELS)))\n",
        "  model.add(MaxPooling3D(pool_size=(1, 4, 4), padding='same', strides=(1,1,1)))\n",
        "  model.add(BatchNormalization(center=True, scale=True))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv3D(64, kernel_size=(1, 4, 4), padding='same', strides=(1,1,1), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling3D(pool_size=(1, 4, 4), padding='same', strides=(1,1,1)))\n",
        "  model.add(BatchNormalization(center=True, scale=True))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Flatten(data_format='channels_last'))\n",
        "  \n",
        "  model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(NUMBEROFCLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9m8gbC76WOW"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czT91Azh_OGm"
      },
      "source": [
        "#lets fit\n",
        "model = make3DCNN()\n",
        "model.summary()\n",
        "model.compile(opt, 'categorical_crossentropy', metrics=['acc'], run_eagerly=True)\n",
        "history = model.fit(train, validation_data=valid, epochs=EPOCHS, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQWQdpeEVoML"
      },
      "source": [
        "!cp -r \"/content/chkp\" \"/content/drive/MyDrive/tirocinioWorkingDirectory/datasets/grid/weights/2409ConvLSTM2D\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}